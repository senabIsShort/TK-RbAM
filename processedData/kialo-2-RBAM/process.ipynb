{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, json, re, random\n",
    "from anytree import Node, RenderTree, PreOrderIter, PostOrderIter, Walker\n",
    "from anytree.exporter import JsonExporter\n",
    "from anytree.util import commonancestors\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import product, combinations\n",
    "from scipy import spatial\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_arguments(tableau):\n",
    "    argGroup = tableau[0]\n",
    "    i = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if i > len(tableau) - 1:\n",
    "            # Return if you reach the end of the tableau\n",
    "            return [argGroup]\n",
    "\n",
    "        stance = re.search(r\"(Con|Pro)(?::)\", tableau[i])\n",
    "        if stance == None:\n",
    "            argGroup = argGroup + \" \" + tableau[i]\n",
    "            i+=1\n",
    "        else:\n",
    "            return [argGroup] + group_arguments(tableau[i:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawKialo2Json(input_file):\n",
    "    \"\"\"Uses kialoParser script to parse the Kialo file and convert it to a json file.\n",
    "    script by Edoardo Guido\n",
    "    edoardo.guido.93@gmail.com\n",
    "    https://edoardoguido.com\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Filename of the Kialo debate downloaded as txt.\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionnary containing information about each node, accessible by the node id.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as fi:\n",
    "        lines = []\n",
    "        for line in fi:\n",
    "            if line.startswith(\"Sources:\"):\n",
    "                break\n",
    "            lines.append(line.strip())\n",
    "\n",
    "        lines = [x for x in lines if x]\n",
    "\n",
    "        # list containing each parsed comment\n",
    "        result = []\n",
    "\n",
    "        # we remove the first two lines of the text\n",
    "        # as we don't need the header\n",
    "        header = []\n",
    "        for line in range(0, 4):\n",
    "            header.append(lines.pop(0))\n",
    "\n",
    "        subject = header[1]\n",
    "\n",
    "        lines = group_arguments(lines)\n",
    "\n",
    "        ##                                            ##\n",
    "        ##                 REGEDITS                   ##\n",
    "        ##                                            ##\n",
    "        # iterate every row in the text file\n",
    "        counter = 1\n",
    "        for line in lines:\n",
    "\n",
    "            # find the tree position the comment is in\n",
    "            tree =  re.search(r\"^(\\d{1,}.)+\", line)\n",
    "\n",
    "            # find if the comment is Pro or Con\n",
    "            stance = re.search(r\"(Con|Pro)(?::)\", line)\n",
    "\n",
    "            # find the text of the comment\n",
    "            content = re.search(r\"((Con|Pro)(?::\\s))(.*)\", line)\n",
    "\n",
    "            # define the hierarchy of the current comment\n",
    "            # which is based on the tree structure\n",
    "\n",
    "            parsed = re.findall(r\"(\\d{1,}(?=\\.))+\", tree.group())\n",
    "            level = len(parsed)-1\n",
    "\n",
    "            # make a dictionary with the single entry\n",
    "            # and put it at the end of the list\n",
    "            result.append({\n",
    "                \"Tree\": tree.group(),\n",
    "                \"Level\": level,\n",
    "                \"Stance\": stance.group(1),\n",
    "                \"ToneInput\": content.group(3),\n",
    "                \"node_id\":subject.replace(\" \",\"_\")+\"_\"+str(counter)\n",
    "            })\n",
    "\n",
    "            counter+=1\n",
    "        \n",
    "        to_write = json.dumps(result, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "\n",
    "    trees = [x[\"Tree\"] for x in result]\n",
    "    trees = ['1.'] + trees\n",
    "\n",
    "    resultAsDict = { x[\"Tree\"]: x for x in result }\n",
    "\n",
    "    id2Node = {}\n",
    "\n",
    "\n",
    "    for idNode in trees:\n",
    "        if idNode == '1.':\n",
    "            id2Node[idNode] = Node(idNode, node_id=-1)\n",
    "        else:\n",
    "            parentId = idNode[:idNode[:-1].rfind(\".\")+1]\n",
    "            id2Node[idNode] = Node(idNode,\n",
    "                                    parent=id2Node[parentId],\n",
    "                                    tree=resultAsDict[idNode][\"Tree\"], \n",
    "                                    level=resultAsDict[idNode][\"Level\"], \n",
    "                                    stance=resultAsDict[idNode][\"Stance\"], \n",
    "                                    toneInput=resultAsDict[idNode][\"ToneInput\"], \n",
    "                                    subject=subject,\n",
    "                                    node_id=resultAsDict[idNode][\"node_id\"]\n",
    "    )\n",
    "\n",
    "    return id2Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickRandomNodePair(tree):\n",
    "    nodes = [node.name for node in PreOrderIter(tree['1.'])]\n",
    "    # Remove root from list of choices\n",
    "    nodes.pop(0)\n",
    "    node1_name, node2_name = random.sample(nodes, 2)\n",
    "    return node1_name, node2_name\n",
    "\n",
    "def getCommonAncestor(tree, node1_name, node2_name):\n",
    "    return commonancestors(tree[node1_name], tree[node2_name])\n",
    "\n",
    "def distanceBetweenPair(tree, node1_name, node2_name):\n",
    "    walker = Walker()\n",
    "    path = walker.walk(tree[node1_name], tree[node2_name])\n",
    "    upwards, _, downwards = path\n",
    "    return len(upwards) + len(downwards)\n",
    "\n",
    "def getNeutralPair(tree, threshold):\n",
    "    \"\"\"From given tree, pick 2 nodes that are at least `threshold` distance apart and have the root as their only common ancestor (i.e. arguments that aren't directly related)\n",
    "\n",
    "    Args:\n",
    "        tree (dict): dictionary of nodes\n",
    "        threshold (int): minimum distance between nodes\n",
    "\n",
    "    Raises:\n",
    "        LookupError: Raised if a pair of nodes that satisfy the conditions cannot be found after 1000 attempts\n",
    "\n",
    "    Returns:\n",
    "        tuple(str, str): Pair of node names\n",
    "    \"\"\"\n",
    "    attempt_limit = 1000\n",
    "    for _ in range(attempt_limit):\n",
    "        n1, n2 = pickRandomNodePair(tree)\n",
    "        rootIsOnlyCommonAncestor = len(getCommonAncestor(tree, n1, n2)) == 1\n",
    "        if not rootIsOnlyCommonAncestor:\n",
    "            continue\n",
    "        # First version used a tree walk to compute distance\n",
    "        # distance = distanceBetweenPair(tree, n1, n2)\n",
    "        # Use the already set 'level' attribute of the node to compute it instead\n",
    "        distance = tree[n1].level + tree[n2].level\n",
    "        if distance < threshold:\n",
    "            continue\n",
    "        return n1, n2\n",
    "    raise LookupError(f\"Could not find a pair of nodes that satisfy the conditions after {attempt_limit} attempts\")\n",
    "\n",
    "def getAllNeutralPairsFromSameTree(tree, threshold):\n",
    "    \"\"\"Get all pairs of nodes that are at least `threshold` distance apart and have the root as their only common ancestor (i.e. arguments that aren't directly related)\n",
    "\n",
    "    Args:\n",
    "        tree (dict): dictionary of nodes representing the tree\n",
    "        threshold (int): minimum distance between nodes\n",
    "\n",
    "    Returns:\n",
    "        list(tuple(str, str)): List of pairs of node names\n",
    "    \"\"\"\n",
    "    root = tree['1.']\n",
    "    if root.children is None:\n",
    "        return []\n",
    "\n",
    "    branches = []\n",
    "    for child in root.children:\n",
    "        # generate list of nodes for each \n",
    "        branches.append([node.name for node in PostOrderIter(child)])\n",
    "\n",
    "    nodePairs = []    \n",
    "    for branchPair in combinations(branches, 2):\n",
    "        # generate combination of each node in each branch\n",
    "        nodePairs += list(product(branchPair[0], branchPair[1]))\n",
    "    \n",
    "    neutralPairs = []\n",
    "    for n1, n2 in tqdm(nodePairs, desc=\"Finding neutral pairs\"):\n",
    "        if n1 == n2:\n",
    "            continue\n",
    "        if (n1, n2) in neutralPairs:\n",
    "            continue\n",
    "        rootIsOnlyCommonAncestor = len(getCommonAncestor(tree, n1, n2)) == 1\n",
    "        if not rootIsOnlyCommonAncestor:\n",
    "            continue\n",
    "        # First version used a tree walk to compute distance\n",
    "        # distance = distanceBetweenPair(tree, n1, n2)\n",
    "        # Use the already set 'level' attribute of the node to compute it instead\n",
    "        distance = tree[n1].level + tree[n2].level\n",
    "        if distance < threshold:\n",
    "            continue\n",
    "        # Here, could add test via embedding similarity\n",
    "        neutralPairs.append((n1, n2))\n",
    "    return neutralPairs\n",
    "\n",
    "def getAllNeutralPairsFromDiffTrees(t1, t2):\n",
    "    \"\"\"Get all pairs of nodes that are from different trees (i.e. arguments that aren't directly related)\n",
    "\n",
    "    Args:\n",
    "        t1 (dict): dictionnary of nodes for the first tree\n",
    "        t2 (dict): dictionnary of nodes for the second tree\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: List of pairs of node names\n",
    "    \"\"\"\n",
    "    nodes1 = [node.name for node in PostOrderIter(t1['1.'])]\n",
    "    nodes2 = [node.name for node in PostOrderIter(t2['1.'])]\n",
    "    # Remove roots from lists of choices\n",
    "    nodes1.pop()\n",
    "    nodes2.pop()\n",
    "    neutralPairs = list(product(nodes1, nodes2))\n",
    "    return neutralPairs\n",
    "\n",
    "def getNNeutralPairsFromSameTrees(tree, threshold, n = 1000):\n",
    "    \"\"\"Get `n` pairs of nodes that are at least `threshold` distance apart and have the root as their only common ancestor (i.e. arguments that aren't directly related)\n",
    "\n",
    "    Args:\n",
    "        t1 (dict): dictionnary of nodes\n",
    "        threshold (int): minimum distance between nodes\n",
    "        n (int, optional): Number of pairs to generate. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: List of pairs of node names\n",
    "    \"\"\"\n",
    "    root = tree['1.']\n",
    "    if root.children is None:\n",
    "        return []\n",
    "\n",
    "    # Only generate pairs of arguments that are in different branches\n",
    "    # This guarantees that the root is the only common ancestor\n",
    "    branches = []\n",
    "    for child in root.children:\n",
    "        # generate list of nodes for each \n",
    "        branches.append([node.name for node in PostOrderIter(child)])\n",
    "\n",
    "    nodePairs = []\n",
    "    for branchPair in combinations(branches, 2):\n",
    "        # generate combination of each node in each branch\n",
    "        # same as [(x,y) for x in branchPair[0] for y in branchPair[1]]\n",
    "        nodePairs += list(product(branchPair[0], branchPair[1]))\n",
    "    \n",
    "    # Shuffle the list of pairs to avoid bias\n",
    "    random.shuffle(nodePairs)\n",
    "    neutralPairs = []\n",
    "    # Keep generating pairs until we have enough\n",
    "    while len(neutralPairs) < n and nodePairs:\n",
    "        n1, n2 = nodePairs.pop()\n",
    "        # The three tests below are redundant, but kept just in case\n",
    "        if n1 == n2:\n",
    "            continue\n",
    "        if (n1, n2) in neutralPairs:\n",
    "            continue\n",
    "        rootIsOnlyCommonAncestor = len(getCommonAncestor(tree, n1, n2)) == 1\n",
    "        if not rootIsOnlyCommonAncestor:\n",
    "            continue\n",
    "        # First version used a tree walk to compute distance\n",
    "        # distance = distanceBetweenPair(tree, n1, n2)\n",
    "        # Use the already set 'level' attribute of the node to compute it instead\n",
    "        distance = tree[n1].level + tree[n2].level\n",
    "        if distance < threshold:\n",
    "            continue\n",
    "        # Here, could add test via embedding similarity\n",
    "        neutralPairs.append((n1, n2))\n",
    "    \n",
    "    return neutralPairs\n",
    "\n",
    "def getNNeutralPairsFromDiffTrees(t1, t2, n = 1000):\n",
    "    \"\"\"Get `n` pairs of nodes that are from different trees (i.e. arguments that aren't directly related)\n",
    "\n",
    "    Args:\n",
    "        t1 (dict): dictionnary of nodes for the first tree\n",
    "        t2 (dict): dictionnary of nodes for the second tree\n",
    "        n (int, optional): Number of pairs to generate. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: List of pairs of node names\n",
    "    \"\"\"\n",
    "    allNeutralPairs = getAllNeutralPairsFromDiffTrees(t1, t2)\n",
    "    neutralPairs = random.sample(allNeutralPairs, n)\n",
    "    return neutralPairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argumentTree2argumentPairTree(node, domains):    \n",
    "    pairs = []\n",
    "    \n",
    "    if len(node.children) == 0:\n",
    "        return pairs\n",
    "    elif node.children != None:\n",
    "        for child in node.children:\n",
    "            if node.name != \"1.\":\n",
    "                pair = {\n",
    "                    \"topArgument\"       :   node.toneInput,\n",
    "                    \"subArgument\"       :   child.toneInput,\n",
    "                    \"subject\"           :   child.subject,\n",
    "                    \"subArgumentLevel\"  :   child.level,\n",
    "                    \"domain\"            :   domains,\n",
    "                    \"sameTree\"        :   True\n",
    "                }\n",
    "                if child.stance == \"Con\":\n",
    "                    pair[\"relation\"] = \"attack\"\n",
    "                else:\n",
    "                    pair[\"relation\"] = \"support\"\n",
    "                pairs.append(pair)\n",
    "\n",
    "            pairs += argumentTree2argumentPairTree(child, domains)\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodePair2NeutralArgPair(node1, node2, domains_n1, domains_n2, same_tree):\n",
    "    pair = {\n",
    "            \"topArgument\"       :   node1.toneInput,\n",
    "            \"subArgument\"       :   node2.toneInput,\n",
    "            \"relation\"          :   \"neutral\"\n",
    "        }\n",
    "\n",
    "    if same_tree:\n",
    "        pair[\"subject\"] = node1.subject\n",
    "        pair[\"domain\"] = domains_n1\n",
    "        pair[\"sameTree\"] = True\n",
    "    else:\n",
    "        pair[\"subject\"] = node1.subject + \" & \" + node2.subject\n",
    "        pair[\"domain\"] = domains_n1 + \" & \" + domains_n2 if domains_n2 else domains_n1\n",
    "        pair[\"sameTree\"] = False\n",
    "\n",
    "    return pair\n",
    "\n",
    "def namePairs2NeutralArgPairs(tree, nodes, domains_n1, tree2=None, domains_n2=None, same_tree=True):\n",
    "    pairs = []\n",
    "    for nodeName1, nodeName2 in nodes:\n",
    "        node1 = tree[nodeName1]\n",
    "        if same_tree:\n",
    "            node2 = tree[nodeName2]\n",
    "        else:\n",
    "            node2 = tree2[nodeName2]\n",
    "\n",
    "        pair = nodePair2NeutralArgPair(node1, node2, domains_n1, domains_n2, same_tree)\n",
    "        pairs.append(pair)\n",
    "\n",
    "        if same_tree:\n",
    "            domains_n2 = domains_n1\n",
    "        reverse_pair = nodePair2NeutralArgPair(node2, node1, domains_n2, domains_n1, same_tree)\n",
    "        pairs.append(reverse_pair)\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kialoUrlIds = pd.read_csv(\"../../rawData/kialo/kialo-url-ids.csv\", index_col=0)\n",
    "pairs = []\n",
    "\n",
    "prev_d = None\n",
    "prev_kialoUrlId = None\n",
    "prev_t = None\n",
    "\n",
    "for i, x in tqdm(kialoUrlIds.iterrows(), total=kialoUrlIds.shape[0]):\n",
    "  try:\n",
    "    d = x.tags\n",
    "    kialoUrlId = x.kialoUrlId\n",
    "\n",
    "    # print(x)\n",
    "\n",
    "    t = rawKialo2Json(\"../../rawData/kialo/debates/en/\"+ kialoUrlId +\".txt\")\n",
    "    \n",
    "    pairs = pairs + argumentTree2argumentPairTree(t['1.'], d)\n",
    "    \n",
    "    # neutralPairsSameTree = getAllNeutralPairsFromSameTree(t, 10)\n",
    "    neutralPairsSameTree = getNNeutralPairsFromSameTrees(t, 10, len(t))\n",
    "    # print(\"Len neutral same tree\", len(neutralPairsSameTree))\n",
    "\n",
    "    pairs = pairs + namePairs2NeutralArgPairs(t, neutralPairsSameTree, d)\n",
    "    \n",
    "    if prev_d is not None and prev_t is not None:\n",
    "      # neutralPairsDiffTree = getAllNeutralPairsFromDiffTrees(t, prev_t)\n",
    "      neutralPairsDiffTree = getNNeutralPairsFromDiffTrees(t, prev_t, max(len(t), len(prev_t)))\n",
    "      # print(\"Len neutral diff tree\", len(neutralPairsDiffTree))\n",
    "      \n",
    "      pairs = pairs + namePairs2NeutralArgPairs(t, neutralPairsDiffTree, d, prev_t, prev_d, same_tree=False)\n",
    "\n",
    "    prev_d = d\n",
    "    prev_kialoUrlId = kialoUrlId\n",
    "    prev_t = t\n",
    "  except Exception as e:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argSrc = [x[\"subArgument\"] for x in pairs]\n",
    "argTrg = [x[\"topArgument\"] for x in pairs]\n",
    "topic = [x[\"domain\"] for x in pairs]\n",
    "relations = [x[\"relation\"] for x in pairs]\n",
    "sameTree = [x[\"sameTree\"] for x in pairs]\n",
    "\n",
    "d = pd.DataFrame.from_dict({\n",
    "  \"topic\": topic,\n",
    "  \"relation\" : relations,\n",
    "  \"argSrc\" : argSrc,\n",
    "  \"argTrg\" : argTrg,\n",
    "  \"sameTree\" : sameTree,\n",
    "})\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.value_counts(\"relation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.value_counts('topic')\n",
    "d['topic'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up \n",
    "\n",
    "The arguments still contain some sources, noted by `[124]` for example. We want to remove those.  \n",
    "Ideally, we should also remove leftover artifacts like mentions of a page number or stuff like `(p. i.)` but that is another hassle for another day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with \"See\" in either argument\n",
    "pattern = r\"-> See (\\d\\.)*\"\n",
    "d = d[~d['argSrc'].str.contains(pattern)]\n",
    "d = d[~d['argTrg'].str.contains(pattern)]\n",
    "\n",
    "# Remove sources from argSrc and argTrg\n",
    "pattern = r\"\\s*\\[\\d+\\]\"\n",
    "d['argSrc'] = d['argSrc'].str.replace(pattern, \"\", regex=True)\n",
    "d['argTrg'] = d['argTrg'].str.replace(pattern, \"\", regex=True)\n",
    "\n",
    "# Remove artifacts like (p. 1), (p. i), (p. ii), (p. 65-66), etc.\n",
    "pattern = r\"\\(\\s*p\\.\\s*[\\di]+(-\\d+)*\\s*\\)\"\n",
    "d['argSrc'] = d['argSrc'].str.replace(pattern, \"\", regex=True)\n",
    "d['argTrg'] = d['argTrg'].str.replace(pattern, \"\", regex=True)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Cosine similarity from embeddings\n",
    "\n",
    "The intuition being that neutral arguments would tend to have orthogonal embeddings, and thus a cosine similarity of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)\n",
    "# model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v2-moe\", trust_remote_code=True)\n",
    "\n",
    "# This model provides the similarity close to 0 for neutrals as opposed to the two above\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", trust_remote_code=True)\n",
    "\n",
    "def getEmbeddingSimilarity(arg1, arg2):\n",
    "    return 1 - spatial.distance.cosine(arg1, arg2)\n",
    "\n",
    "def getEmbeddingsFromArgs(args, model):\n",
    "    # For nomic models with prompt prefix\n",
    "    # prompt_prefix = 'clustering: '    \n",
    "    prompt_prefix = ''    \n",
    "    sentences = []\n",
    "    for arg in list(args):\n",
    "        sentence = prompt_prefix+arg\n",
    "        sentences.append(sentence)\n",
    "    embeddings = model.encode(sentences)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPPORT\n",
    "embedsSupp = getEmbeddingsFromArgs([\"Purity pledges lead to people not having a proper understanding of the potential consequences of sex.\", \"Purity pledges lead to people having a poorer understanding of sexuality.\"], model)\n",
    "\n",
    "# ATTACK\n",
    "embedsAtt = getEmbeddingsFromArgs([\"There is no guarantee that a pledger will be part of an abstinence programme.\", \"Abstinence programmes are likely to lead to people engaging in unsafe sex.\"], model)\n",
    "\n",
    "# NEUTRAL\n",
    "embedsNeut = getEmbeddingsFromArgs([\"In the US, around 2.2 million people are employed in the banking industry in 2023.\", \"Some coffee producers argue that both Fairtrade and Direct Trade standards are necessary to continue sustainable operations.\"], model)\n",
    "\n",
    "print(\"Support : \", getEmbeddingSimilarity(embedsSupp[0], embedsSupp[1]))\n",
    "print(\"Attack\", getEmbeddingSimilarity(embedsAtt[0], embedsAtt[1]))\n",
    "print(\"Neutral\", getEmbeddingSimilarity(embedsNeut[0], embedsNeut[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"Computing similarity for all pairs\")\n",
    "\n",
    "def computeRowCosineSimilarity(row):\n",
    "    embeddings = getEmbeddingsFromArgs([row[\"argSrc\"], row[\"argTrg\"]], model)\n",
    "    return getEmbeddingSimilarity(embeddings[0], embeddings[1])\n",
    "\n",
    "d['similarity'] = d.progress_apply(lambda row: computeRowCosineSimilarity(row), axis=1)\n",
    "\n",
    "supp = d[d['relation'] == 'support']\n",
    "att = d[d['relation'] == 'attack']\n",
    "neut_sameTree = d[(d['relation'] == 'neutral') & (d['sameTree'] == True)]\n",
    "neut_diffTree = d[(d['relation'] == 'neutral') & (d['sameTree'] == False)]\n",
    "neut = pd.concat([neut_sameTree, neut_diffTree], ignore_index=True)\n",
    "\n",
    "d.to_csv(\"kialoPairsRaw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean cosine similarity and std for each relation\n",
    "print(\"Support : \", supp[\"similarity\"].mean(), '+/-', supp[\"similarity\"].std())\n",
    "print(\"Attack : \", att[\"similarity\"].mean(), '+/-', att[\"similarity\"].std())\n",
    "print(\"Neutral : \", neut[\"similarity\"].mean(), '+/-', neut[\"similarity\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity stats on mixed Neutral relations (same and different tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neut[\"similarity\"].describe())\n",
    "neut[\"similarity\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity stats on neutral relations from same Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neut_sameTree[\"similarity\"].describe())\n",
    "neut_sameTree[\"similarity\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity stats on neutral relations from different Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neut_diffTree[\"similarity\"].describe())\n",
    "neut_diffTree[\"similarity\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing\n",
    "\n",
    "The idea here is to keep only the pairs of neutral arguments that are most neutral, by using the computed Cosine similarity between their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kp = pd.read_csv(\"./kialoPairsRaw.csv\")\n",
    "\n",
    "kp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the neutrality based on different similarity scores\n",
    "\n",
    "Let's see if the pairs with negative or close to 0.0 similarity scores are more neutral than others.\n",
    "\n",
    "### Same Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import fill\n",
    "\n",
    "kp_neut_sameTree= kp[(kp['relation'] == 'neutral') & (kp['sameTree'] == True)]\n",
    "below_zero = kp_neut_sameTree[kp_neut_sameTree['similarity'] < 0]\n",
    "\n",
    "samples = below_zero.sample(3).values\n",
    "for row in range(3): \n",
    "    print(\"'topic : \", samples[row][0])\n",
    "    print(\"Arg 1 : \", fill(samples[row][2], 140))\n",
    "    print(\"Arg 2 : \", fill(samples[row][3], 140))\n",
    "    print(\"Similarity \", samples[row][5])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sim = kp_neut_sameTree['similarity'].mean()\n",
    "std_sim = kp_neut_sameTree['similarity'].std()\n",
    "print(\"Mean\", mean_sim, \"\\nStd\", std_sim,\"\\n\")\n",
    "around_mean = kp_neut_sameTree[(kp_neut_sameTree['similarity'] > mean_sim - std_sim) & (kp_neut_sameTree['similarity'] < mean_sim + std_sim)]\n",
    "\n",
    "samples = around_mean.sample(3).values\n",
    "for row in range(3): \n",
    "    print(\"'topic : \", samples[row][0])\n",
    "    print(\"Arg 1 : \", fill(samples[row][2], 140))\n",
    "    print(\"Arg 2 : \", fill(samples[row][3], 140))\n",
    "    print(\"Similarity \", samples[row][5])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows below zero : \", below_zero.value_counts('relation')['neutral'])\n",
    "print(\"Number of rows around the mean : \", around_mean.value_counts('relation')['neutral'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pairs with similarity below zero are clearly not related, they almost look like they're from different trees altogether. It is a safe bet to use them for our dataset.\n",
    "\n",
    "### Different Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_neut_diffTree= kp[(kp['relation'] == 'neutral') & (kp['sameTree'] == False)]\n",
    "below_zero = kp_neut_diffTree[kp_neut_diffTree['similarity'] < 0]\n",
    "\n",
    "samples = below_zero.sample(3).values\n",
    "for row in range(3): \n",
    "    print(\"'topic : \", samples[row][0])\n",
    "    print(\"Arg 1 : \", fill(samples[row][2], 140))\n",
    "    print(\"Arg 2 : \", fill(samples[row][3], 140))\n",
    "    print(\"Similarity \", samples[row][5])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sim = kp_neut_diffTree['similarity'].mean()\n",
    "std_sim = kp_neut_diffTree['similarity'].std()\n",
    "print(\"Mean\", mean_sim, \"\\nStd\", std_sim,\"\\n\")\n",
    "around_mean = kp_neut_diffTree[(kp_neut_diffTree['similarity'] > mean_sim - std_sim) & (kp_neut_diffTree['similarity'] < mean_sim + std_sim)]\n",
    "\n",
    "samples = around_mean.sample(3).values\n",
    "for row in range(3): \n",
    "    print(\"'topic : \", samples[row][0])\n",
    "    print(\"Arg 1 : \", fill(samples[row][2], 140))\n",
    "    print(\"Arg 2 : \", fill(samples[row][3], 140))\n",
    "    print(\"Similarity \", samples[row][5])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows below zero : \", below_zero.value_counts('relation'))\n",
    "print(\"Number of rows around the mean : \", around_mean.value_counts('relation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out neutral rows\n",
    "\n",
    "The objective is to have roughly 100k neutrals with a 50:50 split between sameTree and !sameTree in order to have a balanced dataset to sample from.  \n",
    "Using the conclusion from the previous exploration, we can determine that it is safe to keep only the most dissimilar pairs (i.e. based on the similarity score in ascending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_supp = kp.value_counts('relation')['support']\n",
    "nb_att = kp.value_counts('relation')['attack']\n",
    "\n",
    "target_nb_neut = (nb_supp + nb_att)//2\n",
    "\n",
    "nb_supp, nb_att, target_nb_neut, target_nb_neut//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by similarity and keep enough rows reach target_nb_neut\n",
    "kp_neut_sameTree.sort_values('similarity', inplace=True)\n",
    "kp_neut_sameTree = kp_neut_sameTree[:target_nb_neut//2]\n",
    "kp_neut_sameTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by similarity and keep enough rows to reach target_nb_neut\n",
    "kp_neut_diffTree.sort_values('similarity', inplace=True)\n",
    "kp_neut_diffTree = kp_neut_diffTree[:target_nb_neut//2]\n",
    "kp_neut_diffTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate enough neutrals to create a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_supp = kp[kp['relation'] == 'support']\n",
    "kp_att = kp[kp['relation'] == 'attack']\n",
    "\n",
    "kp_final = pd.concat([kp_supp, kp_att, kp_neut_sameTree, kp_neut_diffTree], ignore_index=True)\n",
    "\n",
    "kp_final.value_counts('relation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_final.to_csv(\"kialoPairs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tk-rbam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
